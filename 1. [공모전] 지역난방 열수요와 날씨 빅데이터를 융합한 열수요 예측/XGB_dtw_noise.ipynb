{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import holidays\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_temporary_dtw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 파생변수 생성\n",
    "1. 평일,주말\n",
    "2. 공휴일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일 추출 (0=월요일, 6=일요일)\n",
    "data['TM'] = pd.to_datetime(data['TM'], format='%Y%m%d%H')\n",
    "data['year'] = data['TM'].dt.year\n",
    "data['month'] = data['TM'].dt.month\n",
    "data['day'] = data['TM'].dt.day\n",
    "data['hour'] = data['TM'].dt.hour\n",
    "\n",
    "data['weekday'] = data['TM'].dt.weekday\n",
    "\n",
    "# 평일/주말 구분 (0=평일, 1=주말)\n",
    "data['is_weekend'] = (data['weekday'] >= 5).astype(int)\n",
    "\n",
    "# 한국 공휴일 설정\n",
    "korea_holidays = holidays.Korea(years=range(2021, 2025))\n",
    "\n",
    "# 공휴일 여부 (1=공휴일, 0=평일)\n",
    "data['is_holiday'] = data['TM'].dt.date.apply(lambda x: x in korea_holidays).astype(int)\n",
    "\n",
    "data.drop(\"weekday\",axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fourier_features(df, col, period, order=3, prefix=None):\n",
    "    \"\"\"\n",
    "    Append 2*order Fourier terms for a cyclical column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df      : pd.DataFrame              (original data)\n",
    "    col     : str                       (column holding integers 0-(P-1) or 1-P)\n",
    "    period  : int                       (cycle length, e.g. 24 for hour, 12 for month)\n",
    "    order   : int, default 3            (# harmonics K)\n",
    "    prefix  : str or None               (prefix for new columns; defaults to `col`)\n",
    "    \"\"\"\n",
    "    prefix = prefix or col\n",
    "    out = df.copy()\n",
    "    x = out[col].astype(float)\n",
    "\n",
    "    for k in range(1, order + 1):\n",
    "        angle = 2.0 * np.pi * k * x / period\n",
    "        out[f\"{prefix}_sin{k}\"] = np.sin(angle)\n",
    "        out[f\"{prefix}_cos{k}\"] = np.cos(angle)\n",
    "    return out\n",
    "\n",
    "# Hour\n",
    "data = add_fourier_features(data, col='hour', period=24, order=2, prefix='hour')\n",
    "\n",
    "# Month\n",
    "data = add_fourier_features(data, col='month', period=12, order=2, prefix='month')\n",
    "\n",
    "\n",
    "\n",
    "data['days_in_month'] = data['TM'].dt.days_in_month\n",
    "\n",
    "def fourier_dom(df, order=3, day_col='day', period_col='days_in_month', prefix='dom'):\n",
    "    out = df.copy()\n",
    "    d   = out[day_col].astype(float)\n",
    "    P   = out[period_col].astype(float)\n",
    "    for k in range(1, order + 1):\n",
    "        angle = 2 * np.pi * k * d / P\n",
    "        out[f'{prefix}_sin{k}'] = np.sin(angle)\n",
    "        out[f'{prefix}_cos{k}'] = np.cos(angle)\n",
    "    return out\n",
    "\n",
    "data = fourier_dom(data, order=2,prefix='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "3. 불쾌지수(DI)  \n",
    "DI = 0.4×(Ta + Tw) + 15  → 일반적인 식  \n",
    "Ta : 건구온도  \n",
    "Tw : 습구온도 (없을 시 밑의 식으로)  \n",
    "\n",
    "DI = 9/5×Ta - 0.55×(1 - RH)×(9/5×Ta - 26) + 32  \n",
    "RH : 상대습도 (소수 단위)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_DI(ta, hm):\n",
    "    hm = hm / 100\n",
    "    DI = 1.8*ta - 0.55*(1 - hm)*(1.8*ta - 26) +32\n",
    "    return DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DI_level(di):\n",
    "    if di < 68:\n",
    "        return 0  # 전원 쾌적\n",
    "    elif di < 70:\n",
    "        return 1  # 불쾌감 나타남  \n",
    "    elif di < 75:\n",
    "        return 2  # 10% 정도 불쾌\n",
    "    elif di < 80:\n",
    "        return 3  # 50% 정도 불쾌\n",
    "    elif di < 83:\n",
    "        return 4  # 전원 불쾌\n",
    "    else:\n",
    "        return 5  # 매우 불쾌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DI'] = calculate_DI(data['TA'], data['HM'])\n",
    "data['Discomfort_level'] = data['DI'].apply(DI_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "4. 난방도일 (HDD) \n",
    "\n",
    "원래는 일별로 구하지만 그렇게 하면 같은 값이 24개씩 반복되기 때문에 시간별 난방도일로 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_HDD_features(\n",
    "    data: pd.DataFrame,\n",
    "    *,\n",
    "    branch_col: str = \"branch_ID\",   # 그룹 구분 열\n",
    "    temp_col: str   = \"TA\",          # 시간별 실외 온도\n",
    "    time_col: str   = \"TM\",          # 타임스탬프\n",
    "    base_temp: int  = 18,            # 기준 온도(°C)\n",
    "    windows: tuple  = (7, 30)        # 누적 일수(예: 7일·30일)\n",
    ") -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "\n",
    "    df = df.sort_values([branch_col, time_col])\n",
    "\n",
    "    # 3) 시간별 HDH = (base – TA)^+    (음수면 0으로 잘림)\n",
    "    df[\"hourly_HDH\"] = (base_temp - df[temp_col]).clip(lower=0)\n",
    "\n",
    "    # 4) 최근 N일 누적 HDD — 그룹별 rolling 합계\n",
    "    for days in windows:\n",
    "        hours = 24 * days                        # 창 크기(시간)\n",
    "        df[f\"rolling_HDD_{days}d\"] = (\n",
    "            df\n",
    "            .groupby(branch_col, observed=True)[\"hourly_HDH\"]\n",
    "            .transform(lambda s: s.rolling(window=hours, min_periods=1).sum())\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "# 사용\n",
    "data = create_HDD_features(\n",
    "    data,            # 원본 DataFrame\n",
    "    branch_col=\"branch_ID\",\n",
    "    temp_col=\"TA\",\n",
    "    time_col=\"TM\",\n",
    "    base_temp=18,\n",
    "    windows=(7, 30)  # 7일 및 30일 누적 HDD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### HP 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 그룹별 HP 필터 함수\n",
    "def hp_filter_group(group, column=\"heat_demand\", lam=1600):\n",
    "    \"\"\"\n",
    "    한 그룹(branch_ID)에 대해 HP 필터 적용 후 trend·noise 열을 추가해 돌려줌\n",
    "    \"\"\"\n",
    "    noise, trend     = hpfilter(group[column], lamb=lam)\n",
    "    group            = group.copy()          # 원본 손상 방지\n",
    "    group[\"heat_demand_trend\"]   = trend\n",
    "    group[\"heat_demand_cycle\"]   = noise\n",
    "    return group\n",
    "\n",
    "# 3) 정렬(시간 순서) → 그룹별 apply → 결과를 하나로\n",
    "data = (\n",
    "    data.sort_values([\"branch_ID\", \"TM\"])\n",
    "      .groupby(\"branch_ID\", group_keys=False)\n",
    "      .apply(hp_filter_group)   # <- 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag features 생성\n",
    "def create_lag_features(df, column, lags):\n",
    "    \"\"\"\n",
    "    Create lag features for a specific column in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input DataFrame.\n",
    "    column (str): Column name to create lag features for.\n",
    "    lags (list): List of lag periods to create features for.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame with lag features added.\n",
    "    \"\"\"\n",
    "    for lag in lags:\n",
    "        df[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
    "    return df\n",
    "\n",
    "lag_dict = {'TA':[1,3,6,12,24], 'HM':[1,2,3], 'WS':[1,3],'SI':[1]}\n",
    "\n",
    "# grouped by 'branch_ID'\n",
    "\n",
    "for col, lags in lag_dict.items():\n",
    "    for lag in lags:\n",
    "        data[f\"{col}_lag_{lag}\"] = (\n",
    "            data\n",
    "            .groupby(\"branch_ID\")[col]          # 그룹별 시계열\n",
    "            .transform(lambda s: s.shift(lag))  # 그룹 내부에서만 shift\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수와 피처 분리\n",
    "target_col = 'heat_demand_cycle'\n",
    "exclude_cols = ['TM', target_col, 'year','month', 'day','hour','Unnamed: 0','branch_ID',\"WD\",\"RN_DAY\",'days_in_month', 'heat_demand_trend','heat_demand']\n",
    "feature_cols = [col for col in data.columns if col not in exclude_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=feature_cols,inplace=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['branch_ID'] = data['branch_ID'].astype('category')\n",
    "\n",
    "print(f\"\\nTarget 변수: {target_col}\")\n",
    "print(f\"사용될 Feature 개수: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도 컬럼 추가\n",
    "data['year'] = pd.to_datetime(data['TM']).dt.year\n",
    "\n",
    "# 바로 분할\n",
    "train_data = data[data['year'].isin([2021, 2022])]\n",
    "val_data = data[data['year'] == 2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Branch ID별 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "def find_best_params_by_branch(data: pd.DataFrame, feature_cols: list, target_col: str) -> dict:\n",
    "    best_params_dict = {}\n",
    "    unique_branches = data['branch_ID'].unique()\n",
    "    \n",
    "    # 학습용과 검증용 데이터 분리\n",
    "    train_data = data[data['year'].isin([2021, 2022])].copy()\n",
    "    val_data = data[data['year'] == 2023].copy()\n",
    "    \n",
    "    for branch_id in unique_branches:\n",
    "        print(f\"\\n===== Finding Best Parameters for branch_ID: {branch_id} =====\")\n",
    "        \n",
    "        # 지사별 데이터 필터링\n",
    "        branch_train = train_data[train_data['branch_ID'] == branch_id].copy()\n",
    "        branch_val = val_data[val_data['branch_ID'] == branch_id].copy()\n",
    "        \n",
    "        # 시계열 순서대로 정렬\n",
    "        branch_train = branch_train.sort_values('TM').reset_index(drop=True)\n",
    "        branch_val = branch_val.sort_values('TM').reset_index(drop=True)\n",
    "        \n",
    "        X_train = branch_train[feature_cols]\n",
    "        y_train = branch_train[target_col]\n",
    "        X_val = branch_val[feature_cols]\n",
    "        y_val = branch_val[target_col]\n",
    "        \n",
    "        # 시계열 교차검증 설정 (학습 데이터 내에서)\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # Optuna objective 함수 (CV 적용)\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 500, 5000, step=100),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.7, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "                'gamma': trial.suggest_float('gamma', 1e-8, 0.5, log=True),\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1,\n",
    "                'verbosity': 0\n",
    "            }\n",
    "            \n",
    "            # CV 점수들을 저장할 리스트\n",
    "            cv_scores = []\n",
    "            \n",
    "            # TimeSeriesSplit을 실제로 사용하여 CV 수행\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                \n",
    "                # 모델 생성 및 학습\n",
    "                xgb_model = xgb.XGBRegressor(**params)\n",
    "                xgb_model.fit(X_fold_train, y_fold_train)\n",
    "                \n",
    "                # fold별 예측 및 RMSE 계산\n",
    "                y_pred = xgb_model.predict(X_fold_val)\n",
    "                rmse = np.sqrt(mean_squared_error(y_fold_val, y_pred))\n",
    "                cv_scores.append(rmse)\n",
    "            \n",
    "            # CV 점수들의 평균을 반환 (최적화 목표)\n",
    "            return np.mean(cv_scores)\n",
    "        \n",
    "        print(f\"--- Starting Optuna Hyperparameter Tuning for {branch_id} ---\")\n",
    "        \n",
    "        # Optuna study 생성 및 최적화\n",
    "        study = optuna.create_study(direction='minimize', \n",
    "                                  sampler=optuna.samplers.TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        \n",
    "        # 최적 파라미터로 2023 검증 데이터 평가\n",
    "        best_params = study.best_params.copy()\n",
    "        best_params.update({\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 0\n",
    "        })\n",
    "        \n",
    "        final_model = xgb.XGBRegressor(**best_params)\n",
    "        final_model.fit(X_train, y_train)  # 2021-2022 전체로 학습\n",
    "        y_val_pred = final_model.predict(X_val)  # 2023으로 예측\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        \n",
    "        best_params_dict[branch_id] = study.best_params\n",
    "        print(f\"--- Best Parameters for {branch_id}: {study.best_params} ---\")\n",
    "        print(f\"--- Best CV RMSE for {branch_id}: {study.best_value:.4f} ---\")\n",
    "        print(f\"--- 2023 Validation RMSE for {branch_id}: {val_rmse:.4f} ---\")\n",
    "    \n",
    "    return best_params_dict\n",
    "\n",
    "def train_final_models_with_best_params(data: pd.DataFrame, feature_cols: list, target_col: str, best_params_dict: dict) -> dict:\n",
    "    final_models = {}\n",
    "    unique_branches = data['branch_ID'].unique()\n",
    "    \n",
    "    # 2021-2023 전체 데이터 (최종 학습용)\n",
    "    full_train_data = data[data['year'].isin([2021, 2022, 2023])].copy()\n",
    "    \n",
    "    for branch_id in unique_branches:\n",
    "        print(f\"\\n===== Training Final Model for branch_ID: {branch_id} =====\")\n",
    "        \n",
    "        # 지사별 데이터 필터링 및 정렬\n",
    "        branch_data = full_train_data[full_train_data['branch_ID'] == branch_id].copy()\n",
    "        branch_data = branch_data.sort_values('TM').reset_index(drop=True)\n",
    "        \n",
    "        X = branch_data[feature_cols]\n",
    "        y = branch_data[target_col]\n",
    "        \n",
    "        # 해당 지사의 최적 파라미터 가져오기\n",
    "        best_params = best_params_dict[branch_id].copy()\n",
    "        best_params.update({\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 0\n",
    "        })\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        final_model = xgb.XGBRegressor(**best_params)\n",
    "        final_model.fit(X, y)\n",
    "        \n",
    "        final_models[branch_id] = final_model\n",
    "        print(f\"--- Final model training completed for {branch_id} ---\")\n",
    "    \n",
    "    return final_models\n",
    "\n",
    "def predict_with_final_models(data_pred: pd.DataFrame, models: dict, feature_cols: list) -> pd.DataFrame:\n",
    "    predictions = []\n",
    "    \n",
    "    data_pred_sorted = data_pred.sort_values('branch_ID').copy()\n",
    "    \n",
    "    for branch_id, group_data in data_pred_sorted.groupby('branch_ID'):\n",
    "        print(f\"--- Predicting for branch_ID: {branch_id} ---\")\n",
    "        \n",
    "        if branch_id in models:\n",
    "            model = models[branch_id]\n",
    "            X_pred = group_data[feature_cols]\n",
    "            group_predictions = model.predict(X_pred)\n",
    "            result_data = group_data.copy()\n",
    "            result_data['prediction'] = group_predictions\n",
    "            predictions.append(result_data)\n",
    "    \n",
    "    final_data = pd.concat(predictions).sort_index()\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: 2021-2022 학습, 2023 검증으로 최적 파라미터 찾기\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: Finding Best Parameters using 2021-2022 train, 2023 validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_params_dict = find_best_params_by_branch(data, feature_cols, target_col)\n",
    "\n",
    "# 최적 파라미터 저장\n",
    "joblib.dump(best_params_dict, 'best_params_by_branch_modify1_cv.joblib')\n",
    "print(f\"\\nBest parameters saved for {len(best_params_dict)} branches\")\n",
    "\n",
    "final_models = train_final_models_with_best_params(\n",
    "    data         = train_data,  # <─ 2023 제외\n",
    "    feature_cols = feature_cols,\n",
    "    target_col   = target_col,\n",
    "    best_params_dict = best_params_dict\n",
    ")\n",
    "\n",
    "# 3) 2023 데이터 예측\n",
    "pred_2023 = predict_with_final_models(\n",
    "    data_pred    = val_data,  # <─ 2023만 전달\n",
    "    models       = final_models,\n",
    "    feature_cols = feature_cols\n",
    ")\n",
    "pred_2023 = pred_2023.to_csv('2023_cycle_lag.csv', index=False)\n",
    "\n",
    "# 2단계: 최적 파라미터로 2021-2023 전체 데이터 재학습\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: Training Final Models with 2021-2023 data using best parameters\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_models = train_final_models_with_best_params(data, feature_cols, target_col, best_params_dict)\n",
    "\n",
    "\n",
    "\n",
    "# 최종 모델 저장\n",
    "joblib.dump(final_models, 'final_models_2021_2023_modify1_cv.joblib')\n",
    "print(f\"\\nFinal models saved for {len(final_models)} branches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = pd.read_csv('2023_cycle_lag.csv')\n",
    "trend = pd.read_csv(\"2023_trend_lag.csv\")\n",
    "\n",
    "pred = cycle['prediction'].values + trend['prediction'].values\n",
    "# pred = np.round(pred, 1)\n",
    "real = val_data['heat_demand'].values\n",
    "# real = np.round(val_data['heat_demand'].values)\n",
    "rmse = np.sqrt(mean_squared_error(real, pred))\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_heat_demand(\n",
    "    df: pd.DataFrame,\n",
    "    trend: pd.DataFrame,\n",
    "    cycle: pd.DataFrame,\n",
    "    region: str,\n",
    "    lw: float = 1.0,\n",
    "    show_obs_sum: bool = False,   # ← 실측 합 라인 표시 여부\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    지역별 Heat-Demand · Trend · Cycle   (실측 ↔ 예측) + 예측 합 비교.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df, trend, cycle : 이전과 동일\n",
    "    region           : branch_ID\n",
    "    lw               : 선 굵기\n",
    "    show_obs_sum     : True 면 (trend+cycle) 실측 합도 표시\n",
    "    \"\"\"\n",
    "\n",
    "    # ── 1. TM 타입 통일\n",
    "    for _df in (df, trend, cycle):\n",
    "        _df['TM'] = pd.to_datetime(_df['TM'])\n",
    "\n",
    "    # ── 2. 필터링 · 병합\n",
    "    region_df = df.query(\"branch_ID == @region\").copy()\n",
    "    if region_df.empty:\n",
    "        raise ValueError(f\"'{region}' 지역 데이터가 없습니다.\")\n",
    "\n",
    "    trend_pred = (\n",
    "        trend.query(\"branch_ID == @region\")[['TM', 'prediction']]\n",
    "        .rename(columns={'prediction': 'trend_pred'})\n",
    "    )\n",
    "    cycle_pred = (\n",
    "        cycle.query(\"branch_ID == @region\")[['TM', 'prediction']]\n",
    "        .rename(columns={'prediction': 'cycle_pred'})\n",
    "    )\n",
    "\n",
    "    plot_df = (\n",
    "        region_df\n",
    "        .merge(trend_pred, on='TM', how='left')\n",
    "        .merge(cycle_pred, on='TM', how='left')\n",
    "        .sort_values('TM')\n",
    "    )\n",
    "\n",
    "    # ── 3. 합계 계산\n",
    "    plot_df['pred_sum'] = plot_df['trend_pred'] + plot_df['cycle_pred']\n",
    "    if show_obs_sum:\n",
    "        plot_df['obs_sum'] = (\n",
    "            plot_df['heat_demand_trend'] + plot_df['heat_demand_cycle']\n",
    "        )\n",
    "\n",
    "    # ── 4. 플롯\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 9), sharex=True,\n",
    "                             gridspec_kw={'hspace': 0.35})\n",
    "\n",
    "    # (a) Heat Demand: 실측 vs 예측 합\n",
    "    axes[0].plot(\n",
    "        plot_df['TM'], plot_df['heat_demand'],\n",
    "        label='Observed', color='tab:blue', linewidth=lw\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        plot_df['TM'], plot_df['pred_sum'],\n",
    "        label='Predicted (trend+cycle)', color='tab:red',\n",
    "        linewidth=lw\n",
    "    )\n",
    "    if show_obs_sum:\n",
    "        axes[0].plot(\n",
    "            plot_df['TM'], plot_df['obs_sum'],\n",
    "            label='Observed (trend+cycle)', color='tab:green',\n",
    "            linewidth=lw, linestyle=':'\n",
    "        )\n",
    "    axes[0].set(title=f'Heat Demand – Region {region}')\n",
    "\n",
    "    # (b) Trend: 실측 vs 예측\n",
    "    axes[1].plot(\n",
    "        plot_df['TM'], plot_df['heat_demand_trend'],\n",
    "        label='Observed', color='tab:blue', linewidth=lw\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        plot_df['TM'], plot_df['trend_pred'],\n",
    "        label='Predicted', color='tab:orange', linewidth=lw\n",
    "    )\n",
    "    axes[1].set(title='Trend Component')\n",
    "\n",
    "    # (c) Cycle: 실측 vs 예측\n",
    "    axes[2].plot(\n",
    "        plot_df['TM'], plot_df['heat_demand_cycle'],\n",
    "        label='Observed', color='tab:blue', linewidth=lw\n",
    "    )\n",
    "    axes[2].plot(\n",
    "        plot_df['TM'], plot_df['cycle_pred'],\n",
    "        label='Predicted', color='gold', linewidth=lw\n",
    "    )\n",
    "    axes[2].set(title='Noise Component')\n",
    "\n",
    "    # ── 공통 옵션\n",
    "    for ax in axes:\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "    fig.autofmt_xdate()   # 날짜 라벨 자동 회전\n",
    "    plt.show()\n",
    "\n",
    "plot_heat_demand(val_data,trend,cycle,'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### test data 파생변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"train_temporary_dtw.csv\")\n",
    "data2 = pd.read_csv('test_temporary_dtw.csv')\n",
    "datafull = pd.concat([data1,data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = datafull\n",
    "# 요일 추출 (0=월요일, 6=일요일)\n",
    "data_test['TM'] = pd.to_datetime(data_test['TM'], format='%Y%m%d%H')\n",
    "data_test['year'] = data_test['TM'].dt.year\n",
    "data_test['month'] = data_test['TM'].dt.month\n",
    "data_test['day'] = data_test['TM'].dt.day\n",
    "data_test['hour'] = data_test['TM'].dt.hour\n",
    "\n",
    "data_test['weekday'] = data_test['TM'].dt.weekday\n",
    "\n",
    "# 평일/주말 구분 (0=평일, 1=주말)\n",
    "data_test['is_weekend'] = (data_test['weekday'] >= 5).astype(int)\n",
    "\n",
    "# 한국 공휴일 설정\n",
    "korea_holidays = holidays.Korea(years=range(2021, 2025))\n",
    "\n",
    "# 공휴일 여부 (1=공휴일, 0=평일)\n",
    "data_test['is_holiday'] = data_test['TM'].dt.date.apply(lambda x: x in korea_holidays).astype(int)\n",
    "\n",
    "data_test.drop(\"weekday\",axis=1, inplace=True)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hour\n",
    "data_test = add_fourier_features(data_test, col='hour', period=24, order=2, prefix='hour')\n",
    "\n",
    "# Month\n",
    "data_test = add_fourier_features(data_test, col='month', period=12, order=2, prefix='month')\n",
    "\n",
    "data_test['days_in_month'] = data_test['TM'].dt.days_in_month\n",
    "\n",
    "data_test = fourier_dom(data_test, order=2, prefix='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['DI'] = calculate_DI(data_test['TA'], data_test['HM'])\n",
    "data_test['Discomfort_level'] = data_test['DI'].apply(DI_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = create_HDD_features(\n",
    "    data_test,            # 원본 DataFrame\n",
    "    branch_col=\"branch_ID\",\n",
    "    temp_col=\"TA\",\n",
    "    time_col=\"TM\",\n",
    "    base_temp=18,\n",
    "    windows=(7, 30)  # 7일 및 30일 누적 HDD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped by 'branch_ID'\n",
    "for col, lags in lag_dict.items():\n",
    "    for lag in lags:\n",
    "        data_test[f\"{col}_lag_{lag}\"] = (\n",
    "            data_test\n",
    "            .groupby(\"branch_ID\")[col]          # 그룹별 시계열\n",
    "            .transform(lambda s: s.shift(lag))  # 그룹 내부에서만 shift\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[data_test['year'].isin([2024,2025])]\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수와 피처 분리\n",
    "target_col = 'heat_demand_cycle'\n",
    "exclude_cols = ['TM', target_col, 'year','month', 'day','hour','Unnamed: 0','branch_ID',\"WD\",\"RN_DAY\",'days_in_month', 'heat_demand_trend','heat_demand']\n",
    "feature_cols = [col for col in data.columns if col not in exclude_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['branch_ID'] = data_test['branch_ID'].astype('category')\n",
    "\n",
    "print(f\"\\nTarget 변수: {target_col}\")\n",
    "print(f\"사용될 Feature 개수: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3단계: 2024년 데이터로 최종 예측\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: Making final predictions on 2024 test data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2024년 테스트 데이터 준비 (이미 전처리된 data_test 사용)\n",
    "test_data_2024 = data_test.copy()\n",
    "test_data_for_pred = test_data_2024.drop(columns=[target_col], errors='ignore')\n",
    "\n",
    "# 최종 예측 수행\n",
    "final_predictions = predict_with_final_models(test_data_for_pred, final_models, feature_cols)\n",
    "\n",
    "# 예측 결과 저장\n",
    "prediction_results = np.round(final_predictions['prediction'], 1)\n",
    "pred_df = pd.DataFrame({'pred': final_predictions['prediction']})\n",
    "pred_df.to_csv('2024_pred_cycle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = pd.read_csv('2024_pred_cycle.csv')\n",
    "trend = pd.read_csv('2024_pred_trend.csv')\n",
    "pred = cycle['pred'].values + trend['pred'].values\n",
    "pred = np.round(pred, 1)\n",
    "pred_df = pd.DataFrame({'prediction': pred})\n",
    "pred_df.to_csv('2024_final_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
