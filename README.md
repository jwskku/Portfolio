# 전재우 포트폴리오

## Intro
> 안녕하세요. 성균관대학교 통계학과 데이터마이닝&머신러닝 랩에서 석사과정을 진행중인 전재우입니다.
>
> 저는 데이터를 통해 현상을 이해하고 문제를 해결하는 과정에 흥미를 느끼는 데이터 분석가입니다.
>
> 통계적 지식과 머신러닝, 딥러닝 방법론을 바탕으로 비즈니스 인사이트를 도출하고, 가치를 창출하는 일에 기여하고 싶습니다.
>
> 학부와 대학원 생활중 진행한 데이터 분석을 중심으로 해당 포트폴리오를 구성하게 되었습니다.

<br />

## 사용 가능 언어 및 라이브러리

> ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white) ![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white) ![SAS SQL](https://img.shields.io/badge/SAS%20SQL-105481?style=for-the-badge&logo=sas&logoColor=white)

<br />

## 관심 분야 및 스킬
* 고차원 데이터 분석을 위한 변수 선택 및 차원 축소.  
* PC(Principle component), Factor(요인) 기반 기저변수 탐색.  
* 개인별 특성에 기반한 점수화, 분류모델 및 해석.
* 대용량 데이터 전처리 및 탐색.  

<br />


# 프로젝트  
> 팀단위로 진행한 프로젝트, 공모전을 정리한 내용입니다.
> 
> 자세한 내용 및 시각화 자료는 해당 폴더에 저장되어 있습니다.
> 
> 코드를 제공할 수 없는 내용은 정리본만 작성했습니다.  

<br />

## 1. [공모전] 지역난방 열수요와 날씨 빅데이터를 융합한 열수요 예측

> **관련 URL :** [공모전 페이지](https://bd.kma.go.kr/contest/)
> 
> **핵심 역할 :**  팀장, 데이터 보간 방식 및 주요 분석 개념 제안, 지사별 분석 코드 작성
>
> **주요 방법론 :**  XGboost, 삼각변환(Fourier transformation), HP-filter, DTW
<details>
<summary>열기 / 닫기</summary>

### 사용 언어
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)


### 분석 개요

* 최근 공동주택의 공급과 거주 비중이 증가하면서, 이에 따라 지역난방 수요 역시 지속적으로 확대되고 있다.
* 공동주택의 열 수요는 외부 기상 요인의 영향을 크게 받기 때문에, 기온, 습도, 풍속 등 다양한 기상 변수에 기반한 **정밀한 열수요 예측**이 필요하다.
* 기존의 열수요 기반 데이터 뿐만 아니라 **날씨 빅데이터를 융합**한 열수요 예측 모델을 통해 더 정확한 예측을 목표로 한다.
<br />

### 분석 대상

* **학습 데이터 :** 2021.01.01 부터 2023.12.31 까지의 시계열 데이터가 시간 단위로 관측되었다. (총 499,301개)
* **평가 데이터 :** 2024년 1년의 데이터중 heat_demand를 제외한 나머지 변수가 주어졌을 때 지사별 heat_demand를 예측했다.  
* 총 19개의 지사가 데이터에 포함되어 있고, **대량의 연속결측**이 발생한 변수가 있기 때문에 데이터 전처리가 핵심 과제였다.
* 평가 기준: RMSE
  
  | 변수명 | 설명 |
  | :--- | :--- |
  | tm | 날짜 및 시각 |
  | m_hr1 | 1시간 강수량 |
  | branch_ID | 지사명 |
  | hm | 정시 상대 습도 |
  | ta | 정시기온 |
  | si | ASOS 일사량 |
  | wd | 정시 10분 평균 풍향 |
  | ta_chi | 체감온도 |
  | ws | 정시 10분 평균 풍속 |
  | heat_demand | 시간당 지사별 열 공급량 |
  | m_day | 해당 시간까지의 일 강수량 |
  
<br />

### 분석 방안

##### 결측치 보간
* 기온(ta, 12 997개), 풍향(wd, 18 815개), 풍속(ws, 18 815개), 일강수량(rn_day, 18 626개), 시간 강수량(rn_hr1, 19 154개), 상대습도(hm, 39 717개), 일사량(si, 232 922개), 체감온도(ta_chi, 20개), 열수요(heat_demand, 23개) 변수에 결측치가 확인되었다.

* 연속으로 1개, 2개 결측된 관측값들에 대해서는 시계열 데이터에서 자주 사용되는 선형 보간을 진행했다.

* 3개 이상 연속으로 결측된 경우, 원본 데이터의 지역적 특성과 기상적 특성을 반영하기 위해 직전값과 클러스터 내 평균을 **가중평균**해 사용했다.

* 시계열 데이터에서 정확한 클러스터링을 위해 **DTW(Dynamic Time Warping)**을 기반으로한 계층적 클러스터링을 수행했다.

##### 도메인과 데이터를 고려한 파생변수 생성
* 시간에 대한 효과를 명확히 표한히가 위해 **삼각함수 변환**을 통한 주기성을 표현했다.

* 지연 변수를 통해 lag 효과를 표현해 모델이 학습할 수 있도록 했다.

##### 지사별 시계열 분해 및 모델학습
* 지사별 환경 차이점을 고려해, 지사 각각의 데이터를 통해 개별 모델을 학습했다.

* 시계열 데이터의 큰 추세와 세부적인 변화를 분석하고 변수의 중요도를 해석하기 위해 **HP filter**를 이용한 추세-잔차 이중모형을 설정했다.

* 각 추세-잔차에 대해 validation에서 가장 좋은 성능을 보인 **XGboost + XGboost** 조합을 최최종 모델로 선정했다. 

<br />

### 분석 결과 및 활용

* 최종 도출한 모델을 통해 기존 시행되는 사업중 하나인 **"에코 마일리지"** 사업의 고도화를 제안했다.

* 기존 방식은 전년도 열 사용량을 통해 해당 연도의 사용량 목표를 제시했다. 하지만 이러한 방식은 해당 연도의 기상상황을 전혀 반영하지 못하는 문제가 있다.

* 추세-잔차 모델을 통해 알아낸 세부적인 추세와 잔차의 변화에 영향을 주는 변수를 반영하여 더욱 세부적인 개인 절약 목표를 제시하여 **더 합리적인 목표**를 제공했다.

* 최종 제출 결과: 최종 RMSE 15.53으로 본선에 진출하여 입선했다.

<br />

### 개선점

* 모델에서 도출한 변수 중요도를 통해 더 세부적인 해석 결과를 제공해야한다. 이는 모델에서 분석이 끝나는 것이 아닌 더 세부적인 해석을 통해 실질적인 활용의 영역으로 나아가야 한다. 

* 지사별 데이터를 통해 학습했지만 데이터를 세분화 하면서 모델별 학습 데이터량이 줄어드는 문제가 발생했다. 지사 개별, 클러스터별, 전체 데이터 중 어느 데이터 단위가 더 합당할지 추가적인 기준이 있으면 분석 흐름이 개선될 것이다.

* 분석 당시의 팀원 개인의 편의성을 위해 개발 언어를 통일하지 않고 진행했다. 데이터 전처리 후 파일을 반출하고 후반 분석을 진행했기 때문에 문제가 생기진 않았지만, 추후 개발 및 문서화에 불리점이 있어 이를 개선하는 것이 좋을 것으로 판단된다.

* HP filter 기반 분해에서 각 시간 주기(월,일,시) 단위로 다른 파라메터를 통해 분해가 가능하다. 분석에서는 가장 세부 단위 한가지만을 사용했지만, 다양한 단위를 통해 분해 결과를 다각화 했다면 더 정확하고 해석에 이점이 있는 모델을 작성할 수 있을 것으로 예상된다.

</details>


---

## 2. [프로젝트] 의료 빅데이터 분석을 위한 질병 단계 기반 통합적 데이터과학 방법론 개발

> **관련 URL :** [NTIS 과제 정보](https://www.ntis.go.kr/project/pjtInfo.do?pjtId=2710018202&pageCode=TH_PJT_PJT_DTL)
>
> **핵심 역할 :** 석사연구원, 유전체 데이터 처리 및 질병 유형/원인 분석 모델 구현
>
> **주요 방법론 :** SVM, SIS(Sure Independence Screening), SVS(Sufficient Variable Screening), Permutation test

<details>
<summary>열기 / 닫기</summary>


### 사용 언어
![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)

### 분석 개요

* 의료 빅데이터를 활용하여 질병의 예측, 원인 규명, 진단, 치료, 효과 검증에 이르는 전 과정을 통합적으로 분석하는 것이 목표로 한다.
* 현재 프로젝트는 진행중으로, 질병의 근본적인 원인을 탐색하는 질병 유형/원인 규명 단계의 기초 모델링 연구에 집중하고 있다.
* 궁극적으로는 질병의 효과적인 예방과 치료에 기여하여 의학 및 데이터과학 분야의 학문적 발전에 기여하는 것을 목표로 한다.
<br />

### 분석 대상

* **주요 분석 데이터 :** 질병의 근본적인 유전적 요인을 탐색하기 위한 유전체 데이터를 핵심적으로 다루고 있다.
* **데이터 특징 :** 다수의 유전자 정보를 포함하는 고차원 데이터이며, 분석 결과의 신뢰도에 영향을 미치는 교란 변수가 존재할 가능성이 높다.
<br />

### 분석 방안

##### 질병 발생/원인 규명을 위한 기초 모델링
* 데이터에 비해 차원이 매우 큰 초고차원 상황에서 적절한 변수의 선택 및 차원축소를 위해 여러 **Screening**방법과 **변수 선택** 방법을 비교, 평가했다. 
* 단순한 선형 관계만을 규명하는 것이 아닌, 비선형, 조건부 관계 모두 찾기 위해 <b>SVS(Sufficient Variable Screening)</b>이후 **Pseudo sample SVM-RFE**에 permutation test를 적용했다.

<br />

### 중간 결과 및 기대효과

* **개인 기여 :** 고차원의 유전체 데이터에 대한 변수 선택 파이프라인을 구축했으며, 질병 발생과 관련된 유전자 분석을 위한 기초 모형을 성공적으로 구현했다.
* **기대 효과 :** 본 1차년도 연구를 통해 질병의 근본적인 유전적 원인을 규명하는 모델의 기반을 마련하고, 인과추론의 정확성을 높여 분석 결과의 신뢰도를 확보할 것으로 기대한다.
<br />

### 향후 연구 계획

* **모델 고도화 :** 현재 구현된 기초 모델을 바탕으로, 더 복잡한 유전자 상호작용을 포착할 수 있도록 모델 구조를 발전시킨다.
* **2차년도 연구 연계 :** 1차년도에 개발된 유전자 분석 모델의 결과를 바탕으로, 2차년도에는 질병의 진단 및 치료 단계 모델과의 연계 방안을 개발한다.

</details>

---


## 3. [DACON] Boost up AI 2025 - 신약 개발 경진대회

> **관련 URL :** [데이콘 페이지](https://dacon.io/competitions/official/236518/overview/description)
> 
> **핵심 역할 :** 주요 데이터 해석 및 모델 학습
>
> **주요 방법론 :** LightGBM, RandomForestRegressor, GNN, Model ensemble
<details>
<summary>열기 / 닫기</summary>

### 사용 언어 및 라이브러리
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)


### 분석 개요

* 인체 내 약물 대사의 핵심 효소인 CYP3A4는 전체 Cytochrome P450 대사의 절반 이상을 차지하며, 대부분의 약물 분해에 관여한다.
* CYP3A4의 활성을 조절하는 약물을 함께 복용하면, 혈중 약물 농도가 불안정해져 약효가 감소하거나 부작용 위험이 커질 수 있다.
* 본 연구는 이러한 문제를 해결하기 위해, 약물의 분자 구조만으로 CYP3A4 저해율을 예측하는 AI 모델을 개발하는 것을 목표로 한다.
<br />

### 분석 대상

* **학습 데이터 :** 1,681개의 분자에 대한 고유 구조 문자열(`Canonical SMILES`)과 억제정도(`Inhibition`)가 관측됐다.
* **평가 데이터 :** 100개의 분자에 대한 고유 구조 문자열을 통해 억제정도를 예측했다.  
* **평가 기준 :** NRMSE와 Pearson 상관 계수를 결합한 지표
  
  |`ID` |`Canonical_Smiles` |`Inhibition`|
  |:------|:------|------:|
  |TRAIN_0000	|`Cl.OC1(Cc2cccc(Br)c2)CCNCC1`|12.5|
  |TRAIN_0001	|`Brc1ccc2OCCc3ccnc1c23`|4.45|
  |TRAIN_0002	|`CC1(CO)CC(=NO1)c2cc(c(F)cc2Cl)[N+](=O)[O-]`|4.92|
  
<br />

### 분석 방안

##### 데이터적 특성
* 분자 구조를 나타내는 Canonical_Smiles 문자열로부터 AI 모델이 학습할 수 있는 수치적 특징을 생성하기 위해, rdkit 라이브러리를 사용했다. 이를 통해 약 170종의 물리화학적 기술자와 11가지 종류의 분자 지문(fingerprint)을 계산하여 데이터셋을 생성했다.

* 학습 데이터의 양이 많지 않아 직접 DL 모델을 작성하는 것은 유의하지 않을 것이라고 판단했다. 기본 모델로 고차원 상황을 해결할 수 있는 tree based 모델인 **LigthGBM**을 사용해 생성한 분자 지문들의 성능을 평가했다.

##### 모델 작성과 앙상블
* LigthGBM을 통해 평가된 상위 5개의 분자 지문에 대해서 추가로 **RandomForest**를 작성했다.

* 레이어를 고정한 사전학습 GNN 모델인 **GROVER**를 사용하여 도출한 최종 embeding을 통해 Ridge 회귀모형을 작성했다.
  
  (*레이어 고정 이유: 해당 데이터를 통해 새롭게 학습한 모델 생성이 목적이 아니라 embeding을 통한 변수 추출이 목적)

* 더 robust한 결과를 위해 앙상블을 진행하였고, 가중치는 **optuna**를 통해 도출했다.

<br />

### 분석 결과 및 활용

* Public score 기준 160등, private score 기준 216등으로 대회를 마감했다.

* 예측에 초점이 맞춰진 대회이기 때문에 해석과 변수에 대한 분석은 진행하지 않았다.


<br />

### 개선점

* 주어진 데이터가 고유 구조 문자열과 억제정도뿐이었기에 분석을 위한 변수 생성에 어려움을 겪었다. 데이터에 대한 도메인 지식이 있는 전문가와 협업을 한다면 데이터 준비 단계가 더욱 원활할 것이다.

* 분자 구조또한 네트워크 데이터의 일종으로 파악해 GNN을 활용한 분석이 유의미할것으로 예상했다. 다만 새로운 모델을 전체적으로 학습하기엔 데이터의 수가 너무 적어 사전학습된 모델을 활용했지만, 그다지 좋은 성능을 내지 못했다. 데이터 양과 특성을 고려한 모델 선택에 더 신중하고 근거를 찾을 수 있어야한다.


</details>

---

## 4. [공모전] 클러스터링을 통한 지하수 유형화 및 신규 가뭄취약지역 시설 추천

> **관련 URL :** [공모전 페이지](https://www.gims.go.kr/competPage.do)
> 
> **핵심 역할 :** 팀장, 데이터 수집 및 핵심 분석방법론 제안(군집화 및 유형예측)
>
> **주요 방법론 :** K-means Clustering, RandomForestClassifier
<details>
<summary>열기 / 닫기</summary>

### 사용 언어
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)


### 분석 개요

* 기록적인 마른장마와 가뭄으로 물 부족 현상이 심화됨에 따라, 안정적인 대체 수자원으로서 지하수의 중요성이 커지고 있다.
* 무분별한 지하수 개발은 자원 고갈과 수질 악화를 초래할 수 있어, 데이터에 기반한 체계적인 분석과 관리 전략이 필요하다.
* 본 분석은 가뭄에 취약한 지역의 지하수 데이터를 유형별로 군집화하고, 각 유형의 특성에 맞는 최적의 활용 방안을 도출하여 타 지역에도 적용 가능한 맞춤형 전략을 제시하는 것을 목표로 한다.
<br />

### 분석 대상

* **활용 데이터 :** 국가가뭄정보포털의 가뭄취약성 평가 결과를 바탕으로, 취약성이 높은 V, IV 등급의 12개 시군구 지역의 지하수 관련 데이터를 활용했다.
* 국가지하수정보센터(GIMS)와 국가가뭄정보포털에서 수집한 데이터를 융합하여 분석 데이터셋을 구축했다.


  | 데이터명 | 데이터 내용 | 출처 |
  | :--- | :--- | :--- |
  | 제원정보 | 시도, 시군구 등 위치 정보, 양수능력, 취수계획량, 위경도 등 | GIMS 국가지하수정보센터 |
  | 대수성시험 | 양수량, 자연수위, 안정수위 등 | GIMS 국가지하수정보센터 |
  | 수질검사 일반 | 수질검사종류코드 | GIMS 국가지하수정보센터 |
  | WHPA | 투수량계수, 대수층두께, 연평균강수량, 함양량 등 | GIMS 국가지하수정보센터 |
  | 가뭄 취약성 평가 | 용수공급 가능일수, 가뭄심도, 생공용수 이용량, 보조수원용량 등 | 국가가뭄정보포털 |
  
<br />

### 분석 방안

##### 데이터 전처리
* 여러 데이터테이블에서 데이터를 좌표와 관정 번호 기준으로 합치면서 데이터 중복 문제를 방지하며 데이터 클리닝을 진행했다.

* 수집된 변수들의 상관관계를 분석하여 다중공선성이 높은 변수들을 확인했다. 해당 변수들을 **PCA**를 통해 차원 축소하여, 잠재변수를 표현했다.

##### 클러스터링을 통한 유형화 및 해석
* **K-means clustering**을 수행하여, 유사한 특성을 가진 지하수 그룹을 식별했다.

* 실루엣 계수를 통해 최적의 군집 수(K=5)를 결정하고, 각 군집의 특성을 분석하여 **'대규모 농업/공업 집중형'**, **'고품질 음용수 보존형'** 등 5개의 지하수 유형으로 정의했다.

##### 신규 지역을 위한 유형 분류기 학습 및 적용
* 군집 분석을 통해 레이블링된 데이터를 기반으로, **Random Forest** 분류 모델을 학습시켰다.

* 신규 지역의 지하수 정보를 입력했을 때, 해당 지역이 5가지 유형 중 어디에 속하는지 분류하는 역할을 한다.

* 이를 통해 새로운 지역에도 기존에 정의된 <b>유형별 맞춤형 시설(대구경 관정, 소규모 농업용 관정 등)</b>을 추천할 수 있는 시스템을 구축했다.

<br />

### 분석 결과 및 활용

* **K-means clustering**을 통해 국내 가뭄취약지역의 지하수를 5가지 뚜렷한 유형으로 분류하고, 각 유형별 수리·수질 특성에 기반한 맞춤형 활용 및 관리 전략을 도출했다.

* 최근 물 부족이 심각한 **강릉시 옥계면** 지역에 적용한 결과, 해당 지역의 지리적 특성(넓은 농경지, 하천 인접)에 부합하는 <b>유형 3(소규모 안정 농업용수형)</b>으로 다수 분류되는 것을 확인했다.

* 분석 결과를 바탕으로 강릉 옥계면 지역에는 대규모 시설보다 '소규모 농업용 관정'을 통한 안정적인 용수 공급이 더 적절하다는 구체적인 시설 추천 근거를 제시했다.

<br />

### 개선점

* 가뭄정보포탈의 보고서가 2021년에 작성되었기 때문에 지하수 관련 자료와 데이터의 발행시기가 맞지 않는 문제가 있었다. 선정한 12개의 지역이 현 시점에도 가뭄취약지역인지 직접 확인했지만, 가뭄정보포탈의 최신 분석결과를 활용한다면 데이터 활용 범위가 더 정확했을 것이다.

* **K-means** 외의 **DBSCAN**을 사용해 편향된 분포에 더 적합한 클러스터링 방법을 사용할 수 있다. 또한 **DBSCAN**은 밀도기반 알고리즘이기에 특이값에 더 강건하다. 이번 분석에서는 대규모 국가시설등 특이값을 직접 처리했지만, 모델로 처리 가능한 방법을 적용할 수 있을 것이다.

* 현 시점의 값을 기준으로 분석이 진행되었지만, 이전 시점의 데이터도 추가하여 지하수의 시계열적 변화도 분석에 추가할 수 있을 것이다.


</details>

---

## 5. [프로젝트] 핵심물품 분석을 통한 30대 조합원 방문 증대 전략

> **관련 URL :** [DNI](https://dni.co.kr/)(교육기관)
> 
> **핵심 역할 :** 교육생, 상품 구매 주기를 통한 물품 선정
>
> **주요 방법론 :** SQL, CRM


<details>
<summary>열기 / 닫기</summary>

  
### 사용 언어
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![SAS SQL](https://img.shields.io/badge/SAS%20SQL-105481?style=for-the-badge&logo=sas&logoColor=white)


### 분석 개요

* 제주의 유통업체 데이터 분석 결과, **30대 조합원의 수에 비해 매출 비중이 현저히 낮은 현상**을 발견했다.
* 특히 조합원 가입이 가장 활발한 **30대 후반(35-39세) 그룹의 거래 건수 성장률이 빠르게 감소**하는 추세를 확인했다.
* 이러한 성장 둔화를 반전시키고 30대 조합원의 방문 및 구매를 활성화하기 위해, 그들의 특성을 반영하는 **핵심물품을 분석하고 이를 기반으로 한 맞춤형 마케팅 전략을 제안**하는 것을 목표로 했다.
<br />

### 분석 대상

* **분석 데이터 :** 해당 업체의 조합원 정보 및 거래 내역 데이터 (기간: 2014.01.01 ~ 2019.06.30)
* **타겟 그룹 :** 전체 조합원 중 **만 35세에서 39세 사이의 일반 조합원**을 핵심 분석 대상으로 선정
* **추가 조건 :** 구매 주기를 유의미한 변수로 활용하기 위해, 분석 기간 내 **6회 이상 방문한 조합원**의 데이터로 한정

<br />

### 분석 방안

##### 핵심물품 정의 및 선정
* 30대 후반 조합원들의 특성을 가장 잘 반영하는 물품을 <b>'핵심물품' </b>으로 정의했다.
* **구매 주기**가 전체 조합원보다 짧거나 동일하고, **구매량**이 전체 대비 높은 물품을 기준으로 1차 후보군을 선정했다.
* 거래량이 적거나 특정 개인의 구매가 과도한 이상치를 제외하여, 최종적으로 **34개의 핵심물품**을 선정했다.

##### 핵심물품 범주화 및 특성 분석
* 선정된 34개 핵심물품에 대한 클러스터링을 진행했고, 특성에 따라 **유아용, 간식용, 조리용** 3개의 범주로 재분류했다.
* 각 범주별로 구매 조합원의 연령, 구매 시간대, 요일, 이용 매장 등 세부적인 구매 패턴을 분석하여 마케팅 전략의 근거를 마련했다.

##### 범주별 맞춤형 마케팅 전략 수립
* **유아용 :** 다른 범주에 비해 구매하는 물품 종류가 적은 특성을 고려, **물품 경험 확대를 목표**로 전략을 수립했다.
* **간식용 :** 매장별 판매량 차이가 큰 점에 착안, **물품 배치(진열) 개선**을 통해 판매를 증대하는 방안을 제안했다.
* **조리용 :** 간편 조리 재료를 선호하는 특성을 파악, 관련 물품의 추가 구매를 유도하기 위한 **레시피 카드** 마케팅을 기획했다.

<br />

### 분석 결과 및 활용

* **유아용 :** 이유식 재료 구매 고객 대상 **간식 물품 교환 프로모션**, 대량 구매 수요가 확인된 **건티슈 구성 확대**를 제안했다.
* **간식용 :** 매장별 진열 위치에 따라 매출 차이가 발생하는 것을 확인, **간식 매대 순환 배치** 및 **이주의 간식 프로모션**을 통한 노출 증대 방안을 제시했다. 또한 조합원 VOC를 반영한 음료 구성 변경을 제안했다.
* **조리용 :** 간편 조리를 선호하는 조합원들을 위해, 핵심물품과 함께 사용할 수 있는 다른 식재료를 자연스럽게 소개하는 **레시피 카드를 제작 및 비치**하여 연관 구매를 유도하는 전략을 수립했다.

<br />

### 개선점

* 전략 효과 측정 : 제안된 마케팅 방안을 실제 매장에 적용하고, **A/B 테스트** 등을 통해 매출 및 방문 건수 변화를 정량적으로 측정하여 전략을 고도화할 필요가 있다.
* 분석 대상 확대: 현재 30대 후반에 집중된 분석을 **다른 연령대(예: 40대 초반)로 확장**하여, 연령대별 특성에 맞는 추가적인 핵심물품을 발굴하고 맞춤형 전략을 제시할 수 있다.
* 자동 최신화 시스템: 핵심물품을 주기적으로 **자동 추출**하고, 구매 패턴 변화를 모니터링할 수 있는 파이프라인을 구축하여 **상시적인 CRM 활동**을 지원하는 시스템을 개발할 수 있다.


</details>

## Contact
> 이메일 : samjw3@skku.edu
