{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import folium\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from branca.element import Template, MacroElement # 범례 생성을 위해 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb1 = pd.read_excel('영향조사/3715_경상북도_전체_영향조사_착정정보.xlsx', header=0)\n",
    "kb2 = pd.read_excel('영향조사/3718_경상북도_전체_영향조사_대수성시험.xlsx', header=0)\n",
    "kb3 = pd.read_excel('영향조사/3721_경상북도_전체_영향조사_암상특성.xlsx', header=0)\n",
    "kb4 = pd.read_excel('영향조사/3725_경상북도_전체_영향조사_WHPA.xlsx', header=0)\n",
    "kb5 = pd.read_excel('영향조사/3723_경상북도_전체_영향조사_수질검사일반.xlsx', header=0)\n",
    "\n",
    "kn1 = pd.read_excel('영향조사/3921_경상남도_전체_영향조사_착정정보.xlsx', header=0)\n",
    "kn2 = pd.read_excel('영향조사/3922_경상남도_전체_영향조사_대수성시험.xlsx', header=0)\n",
    "kn3 = pd.read_excel('영향조사/3922_경상남도_전체_영향조사_암상특성.xlsx', header=0)\n",
    "kn4 = pd.read_excel('영향조사/3922_경상남도_전체_영향조사_WHPA.xlsx', header=0)\n",
    "kn5 = pd.read_excel('영향조사/3922_경상남도_전체_영향조사_수질검사일반.xlsx', header=0)\n",
    "\n",
    "kw1 = pd.read_excel('영향조사/4011_강원특별자치도_전체_영향조사_착정정보.xlsx', header=0)\n",
    "kw2 = pd.read_excel('영향조사/4011_강원특별자치도_전체_영향조사_대수성시험.xlsx', header=0)\n",
    "kw3 = pd.read_excel('영향조사/4012_강원특별자치도_전체_영향조사_암상특성.xlsx', header=0)\n",
    "kw4 = pd.read_excel('영향조사/4013_강원특별자치도_전체_영향조사_WHPA.xlsx', header=0)\n",
    "kw5 = pd.read_excel('영향조사/4012_강원특별자치도_전체_영향조사_수질검사일반.xlsx', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_filter = ['영주시','영덕군','울진군','삼척시','양양군', '함양군', '동해시', '속초시']\n",
    "\n",
    "var_1 = ['영향조사번호', '시도', '시군구', '읍면동', '리', '굴착직경(mm)',\n",
    "        '양수능력(㎥/일)', '취수계획량(㎥/일)', '경도','위도']\n",
    "#  '심도(m)' 대수층 두께랑 상관 높다\n",
    "\n",
    "var_2 = ['양수량','자연수위', '안정수위']\n",
    "# '수위강하량' 안정수위랑 상관 높다\n",
    "\n",
    "var_3 = ['비고']\n",
    "\n",
    "var_4 =[ '투수량계수(㎡/일)','대수층두께(m)', '안정수위도달시간(분)','연평균강수량', '함양량_연평균', '향후개발가능량']\n",
    "\n",
    "var_5 = ['수질검사종류코드']\n",
    "\n",
    "join_key = '영향조사번호'\n",
    "\n",
    "df_names = [f'{prefix}{i}' for prefix in ['kb', 'kn', 'kw'] for i in range(1, 5)]\n",
    "\n",
    "\n",
    "dataframes = {\n",
    "    'kb1': kb1, 'kb2': kb2, 'kb3': kb3, 'kb4': kb4, 'kb5': kb5,\n",
    "    'kn1': kn1, 'kn2': kn2, 'kn3': kn3, 'kn4': kn4, 'kn5': kn5,\n",
    "    'kw1': kw1, 'kw2': kw2, 'kw3': kw3, 'kw4': kw4, 'kw5': kw5,\n",
    "    'kl1': kl1, 'kl2': kl2, 'kl3': kl3, 'kl4': kl4, 'kl5': kl5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1단계: 그룹별(kb, kn, kw) Inner Join ---\n",
    "print(\"--- 1단계: 그룹별 Inner Join 진행 ---\")\n",
    "\n",
    "# 그룹별로 순차적 병합을 수행하는 함수 정의\n",
    "def integrate_group(prefix, dfs_dict, key):\n",
    "    \"\"\"\n",
    "    지정된 prefix를 가진 데이터프레임들을 순차적으로 inner join합니다.\n",
    "    중복되는 열에는 고유한 접미사를 붙여 MergeError를 방지합니다.\n",
    "    \"\"\"\n",
    "    # 첫 번째 데이터프레임으로 시작합니다 (예: kb1)\n",
    "    integrated_df = dfs_dict[f'{prefix}1'].copy()\n",
    "    \n",
    "    # 나머지 데이터프레임들(2, 3, 4)을 순차적으로 병합합니다.\n",
    "    for i in range(2, 6):\n",
    "        right_df_name = f'{prefix}{i}'\n",
    "        right_df = dfs_dict[right_df_name]\n",
    "        \n",
    "        integrated_df = pd.merge(\n",
    "            integrated_df,\n",
    "            right_df,\n",
    "            on=key,\n",
    "            how='inner',\n",
    "            # 중복 열에 대해 오른쪽 데이터프레임에만 접미사를 붙입니다.\n",
    "            # 예: '위도' -> '위도_kb2'\n",
    "            suffixes=('', f'_{right_df_name}')\n",
    "        )\n",
    "    return integrated_df\n",
    "\n",
    "# 각 그룹에 대해 병합 함수 실행\n",
    "kb_integrated = integrate_group('kb', dataframes, join_key)\n",
    "kn_integrated = integrate_group('kn', dataframes, join_key)\n",
    "kw_integrated = integrate_group('kw', dataframes, join_key)\n",
    "\n",
    "\n",
    "# --- 2단계: 시군구 필터링 ---\n",
    "print(\"--- 2단계: 시군구 필터링 진행 ---\")\n",
    "\n",
    "kb_filtered = kb_integrated[kb_integrated['시군구'].isin(cities_filter)].copy()\n",
    "kn_filtered = kn_integrated[kn_integrated['시군구'].isin(cities_filter)].copy()\n",
    "kw_filtered = kw_integrated[kw_integrated['시군구'].isin(cities_filter)].copy()\n",
    "\n",
    "\n",
    "# --- 3단계: 최종 변수 선택 ---\n",
    "print(\"--- 3단계: 최종 변수 선택 진행 ---\")\n",
    "\n",
    "# 최종적으로 남길 모든 변수 목록을 정의합니다.\n",
    "# '시군구'와 같은 주소 정보도 포함할 수 있습니다.\n",
    "final_cols_to_keep =  var_1 + var_2 + var_3 + var_4 + var_5\n",
    "\n",
    "# 각 데이터프레임에 존재하는 열만 선택합니다.\n",
    "kb_final = kb_filtered[[col for col in final_cols_to_keep if col in kb_filtered.columns]]\n",
    "kn_final = kn_filtered[[col for col in final_cols_to_keep if col in kn_filtered.columns]]\n",
    "kw_final = kw_filtered[[col for col in final_cols_to_keep if col in kw_filtered.columns]]\n",
    "\n",
    "\n",
    "# --- 4단계: 통합된 데이터프레임 Row-bind ---\n",
    "print(\"--- 4단계: 최종 데이터 Row-bind 진행 ---\")\n",
    "\n",
    "final_df = pd.concat([kb_final, kn_final, kw_final], ignore_index=True)\n",
    "\n",
    "\n",
    "# --- 최종 결과 확인 ---\n",
    "print(\"\\n✔️ 최종 통합 결과:\")\n",
    "print(final_df.head())\n",
    "print(\"\\n✔️ 최종 데이터프레임 정보:\")\n",
    "final_df.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_unique = final_df.drop_duplicates(subset=['영향조사번호'])\n",
    "\n",
    "# To modify the original DataFrame directly, use inplace=True\n",
    "# final_df.drop_duplicates(subset=['영향조사번호'], inplace=True)\n",
    "\n",
    "print(f\"Original number of rows: {len(final_df)}\")\n",
    "print(f\"Number of rows after removing duplicates: {len(final_df_unique)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = final_df_unique.columns.drop('리')\n",
    "\n",
    "\n",
    "# 3. subset 파라미터를 사용하여 '리'를 제외한 열에 결측치가 있는 행 삭제\n",
    "df_cleaned = final_df_unique.dropna(subset=cols_to_check)\n",
    "\n",
    "\n",
    "# 4. 최종 결과 출력\n",
    "print(\"\\n--- '리' 제외 결측치 행 제거 후 ---\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'df_cleaned.csv'\n",
    "df_cleaned.to_csv(file_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "eda 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[df_cleaned['양수량']<=600]\n",
    "df_cleaned = df_cleaned[df_cleaned['취수계획량(㎥/일)']<=600]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. 기본 설정 ---\n",
    "# 한글 폰트 설정 (Windows: Malgun Gothic, macOS: AppleGothic)\n",
    "try:\n",
    "    font_name = fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "    plt.rc('font', family=font_name)\n",
    "except FileNotFoundError:\n",
    "    print(\"Malgun Gothic font not found. Please check your font path.\")\n",
    "# 마이너스 부호 깨짐 방지\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "df = df_cleaned\n",
    "\n",
    "\n",
    "# --- 2. 데이터 기본 정보 확인 ---\n",
    "print(\"\\n--- 2. 데이터 기본 정보 ---\")\n",
    "print(\"\\n[데이터 정보 (info)]\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n[수치형 데이터 기술 통계량 (describe)]\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n[범주형 데이터 기술 통계량 (describe)]\")\n",
    "print(df.describe(include=['object']))\n",
    "\n",
    "\n",
    "# --- 3. 결측치 확인 ---\n",
    "print(\"\\n--- 3. 결측치 확인 ---\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "\n",
    "# --- 4. 수치형 변수 EDA ---\n",
    "print(\"\\n--- 4. 수치형 변수 EDA ---\")\n",
    "# 자동으로 수치형 변수만 선택\n",
    "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# 4-1. 각 수치형 변수의 분포 (히스토그램)\n",
    "print(\"각 수치형 변수의 분포를 히스토그램으로 확인합니다.\")\n",
    "for col in numeric_features:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'\\'{col}\\' 변수 분포')\n",
    "    plt.show()\n",
    "\n",
    "# 4-2. 수치형 변수 간의 상관관계 (히트맵)\n",
    "print(\"\\n수치형 변수 간의 상관관계를 히트맵으로 확인합니다.\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[numeric_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('수치형 변수 상관관계 히트맵')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 5. 범주형 변수 EDA ---\n",
    "print(\"\\n--- 5. 범주형 변수 EDA ---\")\n",
    "# 자동으로 범주형 변수만 선택\n",
    "categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 5-1. 각 범주형 변수의 빈도 (막대 그래프)\n",
    "print(\"각 범주형 변수의 빈도를 막대 그래프로 확인합니다.\")\n",
    "for col in categorical_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(y=col, data=df, order=df[col].value_counts().index)\n",
    "    plt.title(f'\\'{col}\\' 변수 빈도')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "k-means 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "'양수량', '자연수위', '안정수위', '투수량계수(㎡/일)','대수층두께(m)', '연평균강수량', '함양량_연평균', '수질검사종류코드'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. 범주형 변수 처리 (Target Encoding)\n",
    "if '수질검사종류코드' in df_cleaned.columns and '양수량' in df_cleaned.columns:\n",
    "    # '음용수' 관련 카테고리를 하나로 통합합니다.\n",
    "    df_cleaned.loc[df_cleaned['수질검사종류코드'].str.contains('음용수', na=False), '수질검사종류코드'] = '음용수'\n",
    "    \n",
    "    # '양수량'을 기준으로 각 카테고리의 평균값을 계산합니다.\n",
    "    target_mean = df_cleaned.groupby('수질검사종류코드')['양수량'].mean()\n",
    "    \n",
    "    # 계산된 평균값으로 카테고리를 매핑하여 새로운 수치형 변수를 생성합니다.\n",
    "    df_cleaned['수질검사_encoded'] = df_cleaned['수질검사종류코드'].map(target_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncol = ['양수량', '자연수위', '안정수위','수질검사_encoded']\n",
    "#, '함양량_연평균', '향후개발가능량'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_clustering = df_cleaned.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 사용할 최종 변수 목록 업데이트 (원본 변수 제외, 변환된 변수 추가)\n",
    "df_for_clustering = df_for_clustering[knncol_final]\n",
    "\n",
    "\n",
    "# 2-4. 표준화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_for_clustering)\n",
    "\n",
    "\n",
    "# --- 3. 실루엣 계수를 이용한 최적의 K 찾기 ---\n",
    "k_range = range(2, 11)\n",
    "silhouette_scores = []\n",
    "\n",
    "print(\"\\n--- 클러스터 개수(k)별 실루엣 계수 계산 ---\")\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    if len(np.unique(clusters)) > 1:\n",
    "        score = silhouette_score(X_scaled, clusters)\n",
    "        silhouette_scores.append(score)\n",
    "        print(f'k = {k}, 실루엣 계수 = {score:.4f}')\n",
    "    else:\n",
    "        silhouette_scores.append(-1)\n",
    "        print(f'k = {k}, 클러스터가 1개만 생성되어 점수 계산 불가')\n",
    "\n",
    "# --- 4. 실루엣 계수 시각화 ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, silhouette_scores, 'o-')\n",
    "plt.title('클러스터 개수에 따른 실루엣 계수')\n",
    "plt.xlabel('클러스터 개수 (k)')\n",
    "plt.ylabel('실루엣 계수 (Silhouette Score)')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 5. 최적의 K로 최종 클러스터링 수행 ---\n",
    "if silhouette_scores and max(silhouette_scores) != -1:\n",
    "    optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "    print(f'\\n✔️ 실루엣 계수가 가장 높은 최적의 클러스터 개수(k)는 {optimal_k} 입니다.')\n",
    "\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init='auto')\n",
    "    df_for_clustering['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    df_cleaned['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    print('\\n--- 각 클러스터의 데이터 개수 ---')\n",
    "    print(df_for_clustering['cluster'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\n❌ 클러스터링을 수행할 데이터가 없거나 유효한 클러스터를 찾지 못했습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "사용변수 : '양수량', '자연수위', '안정수위','수질검사_endcoded'\n",
    "\n",
    "이용해 클러스터 분류모델 작성 후 강릉 데이터 유형예측 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-1. 분석에 사용할 변수 목록 정의\n",
    "features = ['양수량', '자연수위', '안정수위', '수질검사_encoded']\n",
    "target = 'cluster'\n",
    "\n",
    "# 1-2. 필요한 변수만 선택하고 결측치 제거\n",
    "model_df = df_cleaned[features + [target]].copy()\n",
    "\n",
    "# 1-3. 'cluster' 변수를 범주형(category)으로 변환\n",
    "model_df[target] = model_df[target].astype('category')\n",
    "\n",
    "\n",
    "# --- 2. 모델 학습 및 교차 검증 준비 ---\n",
    "# 설명 변수(X)와 목표 변수(Y) 분리\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 교차 검증 전략 설정 (5-fold Stratified CV)\n",
    "# StratifiedKFold는 각 폴드마다 클러스터의 비율을 동일하게 유지해 줍니다.\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# --- 3. 교차 검증 기반 모델 성능 평가 ---\n",
    "\n",
    "# 3-1. 교차 검증 정확도 점수 계산\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"\\n교차 검증 정확도 점수: {cv_scores}\")\n",
    "print(f\"평균 교차 검증 정확도: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# 3-2. 교차 검증 기반 예측 수행\n",
    "# 각 데이터 포인트가 테스트 데이터로 사용될 때의 예측값을 생성합니다.\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "# 3-3. 분류 리포트 출력\n",
    "print(\"\\n[교차 검증 기반 분류 리포트]\")\n",
    "print(classification_report(y, y_pred_cv))\n",
    "\n",
    "# 3-4. 혼동 행렬 시각화\n",
    "print(\"\\n[교차 검증 기반 혼동 행렬 (Confusion Matrix)]\")\n",
    "cm = confusion_matrix(y, y_pred_cv)\n",
    "plt.figure(figsize=(8, 6))\n",
    "# y.cat.categories를 사용하여 범주 순서에 맞는 라벨을 가져옵니다.\n",
    "labels = y.cat.categories\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('혼동 행렬')\n",
    "plt.xlabel('예측된 클러스터')\n",
    "plt.ylabel('실제 클러스터')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 4. 변수 중요도 확인 ---\n",
    "# 전체 데이터를 사용하여 모델을 최종적으로 학습시킨 후 변수 중요도를 확인합니다.\n",
    "model.fit(X, y)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n--- 클러스터 예측을 위한 변수 중요도 ---\")\n",
    "print(feature_importance)\n",
    "\n",
    "# 변수 중요도를 막대 그래프로 시각화합니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('변수 중요도')\n",
    "plt.xlabel('중요도')\n",
    "plt.ylabel('변수')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl1 = pd.read_excel('영향조사/2639_강원특별자치도_강릉시_영향조사_착정정보.xlsx', header=0)\n",
    "kl2 = pd.read_excel('영향조사/2639_강원특별자치도_강릉시_영향조사_대수성시험.xlsx', header=0)\n",
    "kl3 = pd.read_excel('영향조사/4012_강원특별자치도_전체_영향조사_암상특성.xlsx', header=0)\n",
    "kl4 = pd.read_excel('영향조사/2639_강원특별자치도_강릉시_영향조사_암상특성.xlsx', header=0)\n",
    "kl5 = pd.read_excel('영향조사/2639_강원특별자치도_강릉시_영향조사_수질검사일반.xlsx', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_integrated = integrate_group('kl', dataframes, join_key)\n",
    "final_cols_to_keep = ['영향조사번호','양수량', '자연수위', '안정수위','수질검사종류코드','위도','경도','읍면동','리']\n",
    "kl_final = kl_integrated[[col for col in final_cols_to_keep if col in kw_integrated.columns]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_unique = kl_final.drop_duplicates(subset=['영향조사번호'])\n",
    "\n",
    "# To modify the original DataFrame directly, use inplace=True\n",
    "# final_df.drop_duplicates(subset=['영향조사번호'], inplace=True)\n",
    "\n",
    "print(f\"Original number of rows: {len(kl_final)}\")\n",
    "print(f\"Number of rows after removing duplicates: {len(kl_unique)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = kl_unique.columns.drop(['리','읍면동','위도','경도'])\n",
    "\n",
    "\n",
    "# 3. subset 파라미터를 사용하여 '리'를 제외한 열에 결측치가 있는 행 삭제\n",
    "kl_cleaned = kl_unique.dropna(subset=cols_to_check)\n",
    "\n",
    "\n",
    "# 4. 최종 결과 출력\n",
    "print(kl_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. 범주형 변수 처리 (Target Encoding)\n",
    "if '수질검사종류코드' in kl_cleaned.columns and '양수량' in kl_cleaned.columns:\n",
    "    # '음용수' 관련 카테고리를 하나로 통합합니다.\n",
    "    kl_cleaned.loc[kl_cleaned['수질검사종류코드'].str.contains('음용수', na=False), '수질검사종류코드'] = '음용수'\n",
    "    \n",
    "    # '양수량'을 기준으로 각 카테고리의 평균값을 계산합니다.\n",
    "    target_mean = kl_cleaned.groupby('수질검사종류코드')['양수량'].mean()\n",
    "    \n",
    "    # 계산된 평균값으로 카테고리를 매핑하여 새로운 수치형 변수를 생성합니다.\n",
    "    kl_cleaned['수질검사_encoded'] = kl_cleaned['수질검사종류코드'].map(target_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 새로운 데이터(kl_cleaned)에 대한 예측 수행 ---\n",
    "\n",
    "# 5-1. 예측에 사용할 변수만 선택하고 결측치 처리\n",
    "# 학습에 사용된 features와 동일한 순서로 열을 선택해야 합니다.\n",
    "kl_features = kl_cleaned[features].dropna()\n",
    "\n",
    "# 5-2. 학습된 모델로 클러스터 예측\n",
    "kl_predictions = model.predict(kl_features)\n",
    "\n",
    "# 5-3. 예측 결과를 원본 데이터에 추가\n",
    "# dropna()로 인해 인덱스가 달라졌을 수 있으므로, kl_features의 인덱스를 사용합니다.\n",
    "kl_cleaned.loc[kl_features.index, 'predicted_cluster'] = kl_predictions\n",
    "\n",
    "print(\"\\n--- 새로운 데이터에 대한 예측 결과 ---\")\n",
    "print(kl_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. DMS to DD 변환 함수 (안정성 강화) ---\n",
    "def dms_to_dd_robust(dms_str):\n",
    "    \"\"\"\n",
    "    공백, 특수 문자 등 다양한 구분자를 처리할 수 있는 안정적인 DMS to DD 변환 함수.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = [float(p) for p in re.split(r'[^\\d.]+', str(dms_str)) if p]\n",
    "        if len(parts) == 3:\n",
    "            d, m, s = parts\n",
    "            if not (33 <= d <= 132):\n",
    "                return np.nan\n",
    "            dd = d + m/60 + s/3600\n",
    "            return dd\n",
    "        return np.nan\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "# '위도'와 '경도' 열에 새로운 함수를 적용하여 십진수 좌표 열 생성\n",
    "kl_cleaned['lat_dd'] = kl_cleaned['위도'].apply(dms_to_dd_robust)\n",
    "kl_cleaned['lon_dd'] = kl_cleaned['경도'].apply(dms_to_dd_robust)\n",
    "\n",
    "# 변환 후 결측값이 있는 행은 제거\n",
    "kl_cleaned.dropna(subset=['lat_dd', 'lon_dd'], inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. 지도 생성 ---\n",
    "# 강릉시청을 중심으로 지도 생성 (위도: 37.7555, 경도: 128.8741)\n",
    "m = folium.Map(location=[37.7555, 128.8741], zoom_start=12)\n",
    "\n",
    "# 클러스터 값에 따라 색상을 매핑하는 딕셔너리\n",
    "color_map = {\n",
    "    0: 'blue',\n",
    "    1: 'green',\n",
    "    2: 'red',\n",
    "    3: 'purple',\n",
    "    4: 'orange',\n",
    "    -1: 'gray' # Noise\n",
    "}\n",
    "\n",
    "\n",
    "# --- 4. 지도에 점 찍기 ---\n",
    "# 데이터프레임의 각 행을 순회하며 지도에 점을 추가합니다.\n",
    "for idx, row in kl_cleaned.iterrows():\n",
    "    cluster_num = row['predicted_cluster']\n",
    "    cluster_int = int(cluster_num) # float을 int로 변환\n",
    "    \n",
    "    # 팝업에 표시될 라벨 생성\n",
    "    if cluster_int == -1:\n",
    "        popup_label = 'Noise'\n",
    "    else:\n",
    "        popup_label = f'유형 {cluster_int + 1}'\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat_dd'], row['lon_dd']],\n",
    "        radius=10,\n",
    "        color=color_map.get(cluster_int, 'black'),\n",
    "        fill=True,\n",
    "        fill_color=color_map.get(cluster_int, 'black'),\n",
    "        fill_opacity=0.7,\n",
    "        popup=popup_label # 수정된 라벨을 팝업에 적용\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "# --- 5. 범례(Legend) 추가 (Branca 라이브러리 사용) ---\n",
    "# 범례를 표현할 Jinja2 템플릿을 정의합니다.\n",
    "template = \"\"\"\n",
    "{% macro html(this, kwargs) %}\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; right: 50px; width: 150px; height: auto; \n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color:white; padding: 10px;\">\n",
    "<b>클러스터 범례</b><br>\n",
    "{% for label, color in this.colors.items() %}\n",
    "<i style=\"background:{{ color }}; width:15px; height:15px; display:inline-block; margin-right:5px; border:1px solid grey;\"></i> {{ label }}<br>\n",
    "{% endfor %}\n",
    "</div>\n",
    "{% endmacro %}\n",
    "\"\"\"\n",
    "\n",
    "# 범례에 표시할 항목들을 만듭니다.\n",
    "legend_items = {}\n",
    "for cluster_num in sorted(kl_cleaned['predicted_cluster'].unique()):\n",
    "    cluster_int = int(cluster_num) # float을 int로 변환\n",
    "    \n",
    "    # 범례에 표시될 라벨 생성\n",
    "    if cluster_int == -1:\n",
    "        label = 'Noise'\n",
    "    else:\n",
    "        label = f'유형 {cluster_int + 1}'\n",
    "        \n",
    "    legend_items[label] = color_map.get(cluster_int, 'black')\n",
    "\n",
    "# MacroElement를 사용하여 범례를 생성합니다.\n",
    "macro = MacroElement()\n",
    "macro._template = Template(template)\n",
    "macro.colors = legend_items\n",
    "\n",
    "# 지도에 범례를 추가합니다.\n",
    "m.add_child(macro)\n",
    "\n",
    "\n",
    "# --- 6. 지도 저장 ---\n",
    "# 결과를 HTML 파일로 저장합니다.\n",
    "map_file_path = 'gangneung_map.html'\n",
    "m.save(map_file_path)\n",
    "\n",
    "print(f\"✔️ 지도가 '{map_file_path}' 파일로 성공적으로 저장되었습니다.\")\n",
    "print(\"해당 파일을 웹 브라우저로 열어 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "각 클러스터에 대한 eda 통한 차이점 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프의 모든 글자 크기를 전역적으로 키웁니다.\n",
    "plt.rcParams.update({'font.size': 14,\n",
    "                     'axes.labelsize': 16,\n",
    "                     'axes.titlesize': 18,\n",
    "                     'xtick.labelsize': 12,\n",
    "                     'ytick.labelsize': 12,\n",
    "                     'legend.fontsize': 12,\n",
    "                     'figure.titlesize': 20})\n",
    "\n",
    "\n",
    "# 클러스터 라벨을 알아보기 쉽게 문자열로 변경합니다.\n",
    "cluster_map = {0: '유형 1', 1: '유형 2', 2: '유형 3', 3: '유형 4', 4: '유형 5'}\n",
    "df_cleaned['cluster_label'] = df_cleaned['cluster'].map(cluster_map)\n",
    "\n",
    "\n",
    "# --- EDA 시작 ---\n",
    "\n",
    "# 1. 클러스터별 데이터 개수 확인\n",
    "print(\"--- 1. 클러스터별 데이터 개수 ---\")\n",
    "cluster_counts = df_cleaned['cluster_label'].value_counts().sort_index()\n",
    "print(cluster_counts)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# 2. 수치형 변수 특징 비교\n",
    "print(\"--- 2. 클러스터별 수치형 변수 분포 비교 ---\")\n",
    "numeric_features = ['양수량', '자연수위', '안정수위', '투수량계수(㎡/일)',\n",
    "                    '대수층두께(m)', '연평균강수량', '함양량_연평균']\n",
    "\n",
    "# 2-1. 기술 통계량 비교\n",
    "print(\"\\n[클러스터별 기술 통계량]\")\n",
    "numeric_summary = df_cleaned.groupby('cluster_label')[numeric_features].describe()\n",
    "print(numeric_summary)\n",
    "\n",
    "# 2-2. Boxplot으로 시각적 비교\n",
    "for feature in numeric_features:\n",
    "    if feature in df_cleaned.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x='cluster_label', y=feature, data=df_cleaned, showfliers=False,\n",
    "                    order=sorted(cluster_map.values()))\n",
    "        plt.title(f'클러스터별 {feature} 분포 비교')\n",
    "        plt.xlabel(\"\") # x축 라벨 제거\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# 3. 범주형 변수 특징 비교 (Pie Chart)\n",
    "print(\"\\n--- 3. 클러스터별 범주형 변수 구성 비율 ---\")\n",
    "categorical_features = ['수질검사종류코드']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in df_cleaned.columns:\n",
    "        crosstab_result = pd.crosstab(df_cleaned['cluster_label'], df_cleaned[feature])\n",
    "        crosstab_result = crosstab_result.reindex(sorted(cluster_map.values()))\n",
    "\n",
    "        total_counts = crosstab_result.sum(axis=0)\n",
    "        \n",
    "        n_labels = len(crosstab_result.index)\n",
    "        # subplot 크기를 유동적으로 조절하기 위해 수정\n",
    "        n_rows = (n_labels + 1 + 1) // 2 # 2열 기준으로 행 개수 계산\n",
    "        fig, axes = plt.subplots(n_rows, 2, figsize=(15, 7 * n_rows), squeeze=False)\n",
    "        fig.suptitle(f'클러스터별 {feature} 구성 비율', fontsize=24)\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        colors = ['#87CEEB','#4682B4', '#B0C4DE', '#00BFFF', '#ADD8E6']\n",
    "            \n",
    "        for i, cluster_label in enumerate(crosstab_result.index):\n",
    "            ax = axes[i]\n",
    "            data_for_pie = crosstab_result.loc[cluster_label]\n",
    "            data_for_pie = data_for_pie[data_for_pie > 0]\n",
    "            \n",
    "            ax.pie(data_for_pie, labels=data_for_pie.index, autopct='%1.1f%%', startangle=90, colors=colors,\n",
    "                   textprops={'fontsize': 20})\n",
    "            ax.set_title(cluster_label, fontsize=22)\n",
    "\n",
    "        if n_labels < len(axes):\n",
    "            ax = axes[n_labels]\n",
    "            total_counts_filtered = total_counts[total_counts > 0]\n",
    "            ax.pie(total_counts_filtered, labels=total_counts_filtered.index, autopct='%1.1f%%', startangle=90, colors=colors,\n",
    "                   textprops={'fontsize': 20})\n",
    "            ax.set_title('전체 데이터', fontsize=22)\n",
    "\n",
    "        for i in range(n_labels + 1, len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "            \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터 라벨을 '유형 1', '유형 2' 등으로 매핑\n",
    "cluster_map = {0: '유형 1', 1: '유형 2', 2: '유형 3', 3: '유형 4', 4: '유형 5'}\n",
    "df_cleaned['cluster_label'] = df_cleaned['cluster'].map(cluster_map)\n",
    "\n",
    "# 분석에 사용할 수치형 변수 목록\n",
    "numeric_features = ['양수량', '자연수위', '안정수위', '투수량계수(㎡/일)',\n",
    "                    '대수층두께(m)', '연평균강수량', '함양량_연평균']\n",
    "\n",
    "# 필요한 열만 선택하고 결측치 제거\n",
    "df_for_viz = df_cleaned[['cluster_label'] + numeric_features].dropna()\n",
    "\n",
    "\n",
    "# --- 2. 데이터 스케일링 (Min-Max Scaler) ---\n",
    "scaler = MinMaxScaler()\n",
    "# 수치형 변수들에 대해 스케일링 적용\n",
    "df_for_viz[numeric_features] = scaler.fit_transform(df_for_viz[numeric_features])\n",
    "\n",
    "\n",
    "# --- 3. 클러스터별 평균 계산 및 데이터 재구성 ---\n",
    "# 각 클러스터의 변수별 평균을 계산합니다.\n",
    "cluster_means = df_for_viz.groupby('cluster_label')[numeric_features].mean()\n",
    "\n",
    "# 시각화를 위해 데이터를 'long' 형태로 변환합니다. (Melt)\n",
    "df_melted = cluster_means.reset_index().melt(\n",
    "    id_vars='cluster_label',\n",
    "    var_name='variable',\n",
    "    value_name='scaled_mean'\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4. 시각화 (개별 가로 막대 그래프) ---\n",
    "# 각 클러스터 라벨에 대해 반복하면서 개별 그래프를 생성합니다.\n",
    "for cluster_name in df_melted['cluster_label'].unique():\n",
    "    # 현재 클러스터에 해당하는 데이터만 필터링\n",
    "    cluster_data = df_melted[df_melted['cluster_label'] == cluster_name]\n",
    "    \n",
    "    # 그래프 그릴 공간 생성\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 가로 막대 그래프 생성\n",
    "    ax = sns.barplot(\n",
    "        data=cluster_data,\n",
    "        y='variable',\n",
    "        x='scaled_mean',\n",
    "        color='#00BFFF' # DeepSkyBlue 색상으로 변경\n",
    "    )\n",
    "    \n",
    "    # 그래프 디자인 개선\n",
    "    plt.title(f'{cluster_name} 변수 ', fontsize=24)\n",
    "    plt.xlabel(\"정규화된 평균값\", fontsize=14)\n",
    "    plt.ylabel(\"\") # Y축 라벨 제거\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # 각 막대에 값(value)을 텍스트로 추가\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_width() + 0.01,\n",
    "                p.get_y() + p.get_height() / 2.,\n",
    "                f'{p.get_width():.2f}',\n",
    "                ha='left',\n",
    "                va='center',\n",
    "                fontsize=12)\n",
    "    \n",
    "    # x축의 범위를 약간 늘려 텍스트가 잘 보이도록 함\n",
    "    ax.set_xlim(right=1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터 라벨을 '유형 1', '유형 2' 등으로 매핑\n",
    "cluster_map = {0: '유형 1', 1: '유형 2', 2: '유형 3', 3: '유형 4', 4: '유형 5'}\n",
    "df_cleaned['cluster_label'] = df_cleaned['cluster'].map(cluster_map)\n",
    "\n",
    "# 분석에 사용할 수치형 변수 목록\n",
    "numeric_features = ['양수량', '자연수위', '안정수위', '투수량계수(㎡/일)',\n",
    "                    '대수층두께(m)', '연평균강수량', '함양량_연평균']\n",
    "\n",
    "# 필요한 열만 선택하고 결측치 제거\n",
    "df_for_viz = df_cleaned[['cluster_label'] + numeric_features].dropna()\n",
    "\n",
    "\n",
    "# --- 2. 데이터 스케일링 (Min-Max Scaler) ---\n",
    "scaler = MinMaxScaler()\n",
    "# 수치형 변수들에 대해 스케일링 적용\n",
    "df_for_viz[numeric_features] = scaler.fit_transform(df_for_viz[numeric_features])\n",
    "\n",
    "\n",
    "# --- 3. 클러스터별 평균 계산 및 데이터 재구성 ---\n",
    "# 각 클러스터의 변수별 평균을 계산합니다.\n",
    "cluster_means = df_for_viz.groupby('cluster_label')[numeric_features].mean()\n",
    "\n",
    "# 시각화를 위해 데이터를 'long' 형태로 변환합니다. (Melt)\n",
    "df_melted = cluster_means.reset_index().melt(\n",
    "    id_vars='cluster_label',\n",
    "    var_name='variable',\n",
    "    value_name='scaled_mean'\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4. 시각화 (Faceted Horizontal Bar Plot) ---\n",
    "# catplot을 사용하여 각 클러스터별로 별도의 그래프를 그립니다.\n",
    "g = sns.catplot(\n",
    "    data=df_melted,\n",
    "    y='variable',      # y축에 변수명을 두어 가로 막대 그래프로 변경\n",
    "    x='scaled_mean',   # x축에 값을 두어 가로 막대 그래프로 변경\n",
    "    col='cluster_label', # 'cluster_label' 값에 따라 열을 나눠서 그림\n",
    "    kind='bar',\n",
    "    col_wrap=3,        # 한 줄에 최대 3개의 그래프를 그림\n",
    "    height=5,\n",
    "    aspect=1.2\n",
    ")\n",
    "\n",
    "# 그래프 디자인 개선\n",
    "g.fig.suptitle('클러스터별 변수 프로필 (Min-Max Scaled)', y=1.03, fontsize=24) # 제목 크기 키움\n",
    "g.set_axis_labels(\"정규화된 평균값\", \"\") # 축 라벨 변경\n",
    "g.set_titles(\"{col_name}\", size=18) # 각 subplot의 제목 크기 설정\n",
    "\n",
    "# 각 막대에 값(value)을 텍스트로 추가하는 부분\n",
    "for ax in g.axes.flat:\n",
    "    # ax.patches는 그래프의 각 막대를 의미합니다.\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_width() + 0.01, # 텍스트 x 위치 (막대 끝에서 약간 오른쪽)\n",
    "                p.get_y() + p.get_height() / 2., # 텍스트 y 위치 (막대 중앙)\n",
    "                f'{p.get_width():.2f}', # 표시할 텍스트 (값을 소수점 2자리까지)\n",
    "                ha='left',   # 수평 정렬\n",
    "                va='center', # 수직 정렬\n",
    "                fontsize=12)\n",
    "    # x축의 범위를 약간 늘려 텍스트가 잘 보이도록 함\n",
    "    ax.set_xlim(right=ax.get_xlim()[1] * 1.1)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
